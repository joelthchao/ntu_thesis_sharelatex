\chapter{Conclusion}
\label{c:conc}

In this work we proposed a method called Regularized Sparse Coding to speedup large scale object detection. Our method learns a codebook for the filters from part-based models and conduct operations only on the codebook to reduce computation. The original sparse coding method has accuracy loss problem when the number of classes grows larger, especially when a large speedup is required. Our work first introduces regularization process, which transforms filters and codebook into performance augmented space. Reconstruction in performance augmented space can minimize score map error of filters and achieve large speedup with negligible accuracy loss. To evaluate our method, we conduct experiments and compare our method with the sparse coding method \cite{song2012sparselet}. On VOC2012 we prove that our method can perform better than sparse coding especially when a large speedup is required. On ILSVRC2013 our method reaches a 16 times speedup using only 1.25\% memory with only 0.04 mAP loss compared to the original Deformable Part Model and outperforms the sparse coding method as well. To evaluate the effect of the number of filters on the speedup, we conduct experiments with different filter size and prove that deploying our method on larger filter size can have better accuracy-speedup trade off. Our method can also complement other methods which focus on reducing computation in the proposal extraction stage and parallel computation on GPUs to achieve more speedup. In future, we plan to apply our method on other applications, such as classification and segmentation, to provide speedup without accuracy loss and huge memory usage.
